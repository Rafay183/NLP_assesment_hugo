{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9abbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e60671",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Spending_Pattern_Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e3dba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Merchant_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5812</td>\n",
       "      <td>Restaurants, Fast Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5812</td>\n",
       "      <td>Starbucks Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5813</td>\n",
       "      <td>Movie Theaters, Streaming Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5813</td>\n",
       "      <td>Netflix Subscription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4829</td>\n",
       "      <td>Wire Transfers, Money Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4829</td>\n",
       "      <td>Western Union Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5411</td>\n",
       "      <td>Supermarkets, Grocery Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5411</td>\n",
       "      <td>Whole Foods Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6513</td>\n",
       "      <td>Real Estate Agents, Rental Properties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6513</td>\n",
       "      <td>Airbnb Rental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4121</td>\n",
       "      <td>Taxicabs, Limousines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4121</td>\n",
       "      <td>Uber Ride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5732</td>\n",
       "      <td>Electronics Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5732</td>\n",
       "      <td>Best Buy Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6012</td>\n",
       "      <td>Financial Institutions, Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6012</td>\n",
       "      <td>Chase Bank Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6011</td>\n",
       "      <td>Automated Cash Disburse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6011</td>\n",
       "      <td>ATM Withdrawal - Bank of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5812</td>\n",
       "      <td>Restaurants, Sit-Down Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5812</td>\n",
       "      <td>Olive Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6300</td>\n",
       "      <td>Insurance Sales, Underwriting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6300</td>\n",
       "      <td>State Farm Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4900</td>\n",
       "      <td>Utilities, Electric, Gas, Sanitary, Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4900</td>\n",
       "      <td>Con Edison Bill Payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5967</td>\n",
       "      <td>Direct Marketing - Subscription Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5967</td>\n",
       "      <td>Amazon Prime Subscription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6012</td>\n",
       "      <td>Loan Payments, Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6012</td>\n",
       "      <td>Student Loan Payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5712</td>\n",
       "      <td>Furniture, Home Furnishings Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5712</td>\n",
       "      <td>IKEA Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6211</td>\n",
       "      <td>Securities Brokers, Dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6211</td>\n",
       "      <td>Charles Schwab Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5541</td>\n",
       "      <td>Service Stations (with or without ancillary se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5541</td>\n",
       "      <td>Shell Gas Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7997</td>\n",
       "      <td>Membership Clubs, Gyms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7997</td>\n",
       "      <td>Planet Fitness Membership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5812</td>\n",
       "      <td>Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5812</td>\n",
       "      <td>Chipotle Mexican Grill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5499</td>\n",
       "      <td>Miscellaneous Food Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5499</td>\n",
       "      <td>Trader Joe's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5311</td>\n",
       "      <td>Department Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5311</td>\n",
       "      <td>Macy's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MCC                                      Merchant_Name\n",
       "0   5812                             Restaurants, Fast Food\n",
       "1   5812                                   Starbucks Coffee\n",
       "2   5813                 Movie Theaters, Streaming Services\n",
       "3   5813                               Netflix Subscription\n",
       "4   4829                     Wire Transfers, Money Transfer\n",
       "5   4829                             Western Union Transfer\n",
       "6   5411                       Supermarkets, Grocery Stores\n",
       "7   5411                                 Whole Foods Market\n",
       "8   6513              Real Estate Agents, Rental Properties\n",
       "9   6513                                      Airbnb Rental\n",
       "10  4121                               Taxicabs, Limousines\n",
       "11  4121                                          Uber Ride\n",
       "12  5732                                 Electronics Stores\n",
       "13  5732                               Best Buy Electronics\n",
       "14  6012                      Financial Institutions, Banks\n",
       "15  6012                              Chase Bank Withdrawal\n",
       "16  6011                            Automated Cash Disburse\n",
       "17  6011                   ATM Withdrawal - Bank of America\n",
       "18  5812                       Restaurants, Sit-Down Dining\n",
       "19  5812                                       Olive Garden\n",
       "20  6300                      Insurance Sales, Underwriting\n",
       "21  6300                               State Farm Insurance\n",
       "22  4900          Utilities, Electric, Gas, Sanitary, Water\n",
       "23  4900                            Con Edison Bill Payment\n",
       "24  5967           Direct Marketing - Subscription Services\n",
       "25  5967                          Amazon Prime Subscription\n",
       "26  6012                  Loan Payments, Financial Services\n",
       "27  6012                               Student Loan Payment\n",
       "28  5712                 Furniture, Home Furnishings Stores\n",
       "29  5712                                     IKEA Furniture\n",
       "30  6211                        Securities Brokers, Dealers\n",
       "31  6211                          Charles Schwab Investment\n",
       "32  5541  Service Stations (with or without ancillary se...\n",
       "33  5541                                  Shell Gas Station\n",
       "34  7997                             Membership Clubs, Gyms\n",
       "35  7997                          Planet Fitness Membership\n",
       "36  5812                                             Dining\n",
       "37  5812                             Chipotle Mexican Grill\n",
       "38  5499                          Miscellaneous Food Stores\n",
       "39  5499                                       Trader Joe's\n",
       "40  5311                                  Department Stores\n",
       "41  5311                                             Macy's"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7af68a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6907  \n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6790 \n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6677 \n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6565 \n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6444 \n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6306 \n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6171 \n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6004 \n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5809 \n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5578 \n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5453 \n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5207 \n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4914 \n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4766 \n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4468 \n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4250 \n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4015 \n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3775 \n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3506 \n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3335 \n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3034 \n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2890 \n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2761 \n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2532 \n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2364 \n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2336 \n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2142 \n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2065 \n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1883 \n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1840 \n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1752 \n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1711 \n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1673 \n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1599 \n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1579 \n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1530 \n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1510 \n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1464 \n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1464 \n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1410 \n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1383 \n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1366 \n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1373 \n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1358 \n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1337 \n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1334 \n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1304 \n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1289 \n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1281 \n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1248 \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002484B465CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002484B465CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Data: [0.01490041 0.08570764 0.06577703 0.05828794 0.06130424 0.07532568\n",
      " 0.05192777 0.04009246 0.03373623 0.03908899 0.03039803 0.03954529\n",
      " 0.05260564 0.04216778 0.05130937 0.03842998 0.03645432 0.03872365\n",
      " 0.04386662 0.03915882 0.01787011 0.02769698 0.03247572 0.02218414\n",
      " 0.04085429 0.0261784  0.04160654 0.03601122 0.04666021 0.01888672\n",
      " 0.03138315 0.02819051 0.03593278 0.02864895 0.01501583 0.05182588\n",
      " 0.03587319 0.04409451 0.03542618 0.04270448 0.01790814 0.03270808\n",
      " 0.02361849 0.03475419 0.03253302 0.0291613  0.03760097 0.02542656\n",
      " 0.02535272 0.04685916 0.01667832 0.02727745 0.01879839 0.03048141\n",
      " 0.02223532 0.02230513 0.03965849 0.03876712 0.01905137 0.01858515\n",
      " 0.03345685 0.03622984 0.0185851  0.02539779 0.02284882 0.03438646\n",
      " 0.02579768 0.02363248 0.01847044 0.03542062 0.03040914 0.02508021\n",
      " 0.03223972 0.03639156 0.0239167  0.02846757 0.02878492 0.02648421\n",
      " 0.03110443 0.02779124 0.02223963 0.02679431 0.01909257 0.02665827\n",
      " 0.03191079 0.03254406 0.03273557 0.02892774 0.03484515 0.03491777\n",
      " 0.04707672 0.04210941 0.02823135 0.04205516 0.02182611 0.03504266\n",
      " 0.02600772 0.02643175 0.02354003 0.02082491 0.01951459 0.03154813\n",
      " 0.03967138 0.02652592 0.02899845 0.02600318]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.02960384 0.13428085 0.14453222 0.08717148 0.06669485 0.07343178\n",
      " 0.10644653 0.07704879 0.07049264 0.05407384 0.08414157 0.06428885\n",
      " 0.08308972 0.081607   0.10111619 0.08086033 0.06658334 0.06837747\n",
      " 0.05796595 0.04798401 0.06293052 0.045506   0.05503047 0.05044544\n",
      " 0.05396598 0.03614828 0.09566742 0.05252476 0.07130203 0.0353049\n",
      " 0.05873954 0.04551659 0.05107599 0.04617088 0.04456037 0.05344078\n",
      " 0.05381603 0.06825802 0.06602541 0.04900927 0.04828943 0.0540413\n",
      " 0.04400784 0.0629782  0.05286474 0.07661056 0.07906154 0.04256502\n",
      " 0.06040997 0.06057074 0.04782925 0.0392735  0.05815255 0.04008231\n",
      " 0.04148788 0.05627827 0.05364561 0.05348403 0.06490771 0.05090218\n",
      " 0.05016155 0.0854301  0.052229   0.05656599 0.05839505 0.06683341\n",
      " 0.0466723  0.05753468 0.04665013 0.04727853 0.05850818 0.05785048\n",
      " 0.05925978 0.06374552 0.06632263 0.07815327 0.05637664 0.04522986\n",
      " 0.05971269 0.03520027 0.05209345 0.04692441 0.05264899 0.06534947\n",
      " 0.03926547 0.07027622 0.05939978 0.04942989 0.07623796 0.07337928\n",
      " 0.0619101  0.06910444 0.06729799 0.05560701 0.05302042 0.06060202\n",
      " 0.062938   0.06618486 0.05125771 0.04912464 0.04036941 0.06189251\n",
      " 0.0695809  0.04867433 0.07115109 0.0456026 ]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.01333384 0.06149215 0.11685329 0.05003154 0.04004078 0.03399165\n",
      " 0.02898727 0.0414505  0.03527685 0.06167517 0.03271229 0.03742328\n",
      " 0.02978714 0.03241156 0.04209064 0.04444677 0.05600398 0.02798659\n",
      " 0.03134053 0.0267145  0.02376874 0.02118517 0.03103049 0.04205346\n",
      " 0.04324486 0.01835503 0.0447301  0.02235355 0.04106924 0.02351621\n",
      " 0.02031151 0.0196084  0.02738216 0.01890226 0.01314804 0.0282892\n",
      " 0.04153904 0.03589268 0.03038338 0.03367578 0.0162668  0.01835015\n",
      " 0.02908132 0.02460598 0.03023013 0.037531   0.04536489 0.02082264\n",
      " 0.02380292 0.03449667 0.01558064 0.01912493 0.01708981 0.02232119\n",
      " 0.0214959  0.02091021 0.0276406  0.0400521  0.0305682  0.02698977\n",
      " 0.02567394 0.03312524 0.02009414 0.01844854 0.023047   0.02183021\n",
      " 0.02043578 0.01918682 0.01646014 0.02973365 0.02691637 0.03184363\n",
      " 0.02715669 0.03523187 0.02262555 0.02697586 0.02565367 0.01844995\n",
      " 0.03221616 0.01881036 0.02422779 0.03476119 0.01865712 0.02674178\n",
      " 0.01969358 0.02720243 0.02868712 0.03409804 0.03226721 0.04219358\n",
      " 0.03723737 0.04447927 0.0312669  0.02846856 0.02974593 0.03515235\n",
      " 0.03385006 0.02851856 0.02317512 0.02342553 0.01907782 0.02325376\n",
      " 0.03642816 0.0221905  0.02723243 0.01918064]\n",
      "Label: 5813\n",
      "\n",
      "Data: [0.01466373 0.09258141 0.09972142 0.0856552  0.04759318 0.05795896\n",
      " 0.07013298 0.05935965 0.04137519 0.03729596 0.04182066 0.05646337\n",
      " 0.06620523 0.04391842 0.06545593 0.05148878 0.03851289 0.05030075\n",
      " 0.04019183 0.02898778 0.03112939 0.03026803 0.03352807 0.0382111\n",
      " 0.05236023 0.03834827 0.04458873 0.04169628 0.0663931  0.02519309\n",
      " 0.04279018 0.0385089  0.03664533 0.0321862  0.02528802 0.04460475\n",
      " 0.03408706 0.04116684 0.04601144 0.0435767  0.03859612 0.03903696\n",
      " 0.02391195 0.0505682  0.0512873  0.0330982  0.06486747 0.02889534\n",
      " 0.03535563 0.0380848  0.02562873 0.03160256 0.0325998  0.02826644\n",
      " 0.0353482  0.02990199 0.05384457 0.04153486 0.02742549 0.0278414\n",
      " 0.02958745 0.03724755 0.0288555  0.03138747 0.04327184 0.0467286\n",
      " 0.03804098 0.03297112 0.03188945 0.03687434 0.03780788 0.03609161\n",
      " 0.05044796 0.05129007 0.0431088  0.04453605 0.04092963 0.0339185\n",
      " 0.02882123 0.03078705 0.04194809 0.03348169 0.03360666 0.03678447\n",
      " 0.03519758 0.03998856 0.03198236 0.03332074 0.03794843 0.04552899\n",
      " 0.04303342 0.05191052 0.03695342 0.03511988 0.02858249 0.05243777\n",
      " 0.03233143 0.03570433 0.02462402 0.03127873 0.02069497 0.03325945\n",
      " 0.04490858 0.04286699 0.03272315 0.03178526]\n",
      "Label: 5813\n",
      "\n",
      "Data: [0.00705638 0.0568871  0.06887748 0.05137975 0.02336911 0.0246189\n",
      " 0.04770999 0.02886974 0.01914381 0.02043916 0.02428861 0.02222634\n",
      " 0.0331763  0.0234704  0.0289396  0.02275557 0.02888534 0.03658754\n",
      " 0.0288858  0.01602173 0.01428506 0.01191837 0.01900578 0.01119455\n",
      " 0.02396716 0.01533995 0.03509241 0.03793993 0.03652006 0.01808296\n",
      " 0.02476185 0.01873543 0.01372165 0.0164758  0.01254278 0.01768865\n",
      " 0.0188063  0.01748579 0.02243445 0.01366124 0.01645221 0.01686173\n",
      " 0.01498682 0.01991323 0.01472457 0.01933386 0.02505225 0.01822292\n",
      " 0.02226469 0.02602654 0.01546556 0.01794177 0.01245661 0.01635558\n",
      " 0.00924433 0.01568158 0.01934912 0.01976707 0.01579754 0.01537587\n",
      " 0.01508237 0.01784765 0.01667868 0.01393093 0.0244078  0.01877873\n",
      " 0.01211982 0.01217804 0.01263615 0.02261245 0.02155993 0.02129547\n",
      " 0.01951835 0.02104639 0.01116573 0.01703655 0.01549913 0.01747021\n",
      " 0.01775302 0.01283734 0.01728327 0.02307386 0.01580949 0.02239192\n",
      " 0.0148742  0.02163786 0.02273178 0.01756923 0.02384529 0.02182463\n",
      " 0.02877752 0.02567285 0.01866598 0.01725611 0.01428833 0.01982291\n",
      " 0.0170571  0.01730895 0.01157813 0.01958721 0.00817727 0.01139841\n",
      " 0.03119769 0.01590087 0.0171948  0.01747746]\n",
      "Label: 4829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and lemmatize\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'Merchant_Name' column\n",
    "df['Processed_Description'] = df['Merchant_Name'].\n",
    "Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4e6dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [0.01490041 0.08570764 0.06577703 0.05828794 0.06130424 0.07532568\n",
      " 0.05192777 0.04009246 0.03373623 0.03908899 0.03039803 0.03954529\n",
      " 0.05260564 0.04216778 0.05130937 0.03842998 0.03645432 0.03872365\n",
      " 0.04386662 0.03915882 0.01787011 0.02769698 0.03247572 0.02218414\n",
      " 0.04085429 0.0261784  0.04160654 0.03601122 0.04666021 0.01888672\n",
      " 0.03138315 0.02819051 0.03593278 0.02864895 0.01501583 0.05182588\n",
      " 0.03587319 0.04409451 0.03542618 0.04270448 0.01790814 0.03270808\n",
      " 0.02361849 0.03475419 0.03253302 0.0291613  0.03760097 0.02542656\n",
      " 0.02535272 0.04685916 0.01667832 0.02727745 0.01879839 0.03048141\n",
      " 0.02223532 0.02230513 0.03965849 0.03876712 0.01905137 0.01858515\n",
      " 0.03345685 0.03622984 0.0185851  0.02539779 0.02284882 0.03438646\n",
      " 0.02579768 0.02363248 0.01847044 0.03542062 0.03040914 0.02508021\n",
      " 0.03223972 0.03639156 0.0239167  0.02846757 0.02878492 0.02648421\n",
      " 0.03110443 0.02779124 0.02223963 0.02679431 0.01909257 0.02665827\n",
      " 0.03191079 0.03254406 0.03273557 0.02892774 0.03484515 0.03491777\n",
      " 0.04707672 0.04210941 0.02823135 0.04205516 0.02182611 0.03504266\n",
      " 0.02600772 0.02643175 0.02354003 0.02082491 0.01951459 0.03154813\n",
      " 0.03967138 0.02652592 0.02899845 0.02600318]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.02960384 0.13428085 0.14453222 0.08717148 0.06669485 0.07343178\n",
      " 0.10644653 0.07704879 0.07049264 0.05407384 0.08414157 0.06428885\n",
      " 0.08308972 0.081607   0.10111619 0.08086033 0.06658334 0.06837747\n",
      " 0.05796595 0.04798401 0.06293052 0.045506   0.05503047 0.05044544\n",
      " 0.05396598 0.03614828 0.09566742 0.05252476 0.07130203 0.0353049\n",
      " 0.05873954 0.04551659 0.05107599 0.04617088 0.04456037 0.05344078\n",
      " 0.05381603 0.06825802 0.06602541 0.04900927 0.04828943 0.0540413\n",
      " 0.04400784 0.0629782  0.05286474 0.07661056 0.07906154 0.04256502\n",
      " 0.06040997 0.06057074 0.04782925 0.0392735  0.05815255 0.04008231\n",
      " 0.04148788 0.05627827 0.05364561 0.05348403 0.06490771 0.05090218\n",
      " 0.05016155 0.0854301  0.052229   0.05656599 0.05839505 0.06683341\n",
      " 0.0466723  0.05753468 0.04665013 0.04727853 0.05850818 0.05785048\n",
      " 0.05925978 0.06374552 0.06632263 0.07815327 0.05637664 0.04522986\n",
      " 0.05971269 0.03520027 0.05209345 0.04692441 0.05264899 0.06534947\n",
      " 0.03926547 0.07027622 0.05939978 0.04942989 0.07623796 0.07337928\n",
      " 0.0619101  0.06910444 0.06729799 0.05560701 0.05302042 0.06060202\n",
      " 0.062938   0.06618486 0.05125771 0.04912464 0.04036941 0.06189251\n",
      " 0.0695809  0.04867433 0.07115109 0.0456026 ]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.01333384 0.06149215 0.11685329 0.05003154 0.04004078 0.03399165\n",
      " 0.02898727 0.0414505  0.03527685 0.06167517 0.03271229 0.03742328\n",
      " 0.02978714 0.03241156 0.04209064 0.04444677 0.05600398 0.02798659\n",
      " 0.03134053 0.0267145  0.02376874 0.02118517 0.03103049 0.04205346\n",
      " 0.04324486 0.01835503 0.0447301  0.02235355 0.04106924 0.02351621\n",
      " 0.02031151 0.0196084  0.02738216 0.01890226 0.01314804 0.0282892\n",
      " 0.04153904 0.03589268 0.03038338 0.03367578 0.0162668  0.01835015\n",
      " 0.02908132 0.02460598 0.03023013 0.037531   0.04536489 0.02082264\n",
      " 0.02380292 0.03449667 0.01558064 0.01912493 0.01708981 0.02232119\n",
      " 0.0214959  0.02091021 0.0276406  0.0400521  0.0305682  0.02698977\n",
      " 0.02567394 0.03312524 0.02009414 0.01844854 0.023047   0.02183021\n",
      " 0.02043578 0.01918682 0.01646014 0.02973365 0.02691637 0.03184363\n",
      " 0.02715669 0.03523187 0.02262555 0.02697586 0.02565367 0.01844995\n",
      " 0.03221616 0.01881036 0.02422779 0.03476119 0.01865712 0.02674178\n",
      " 0.01969358 0.02720243 0.02868712 0.03409804 0.03226721 0.04219358\n",
      " 0.03723737 0.04447927 0.0312669  0.02846856 0.02974593 0.03515235\n",
      " 0.03385006 0.02851856 0.02317512 0.02342553 0.01907782 0.02325376\n",
      " 0.03642816 0.0221905  0.02723243 0.01918064]\n",
      "Label: 5813\n",
      "\n",
      "Data: [0.01466373 0.09258141 0.09972142 0.0856552  0.04759318 0.05795896\n",
      " 0.07013298 0.05935965 0.04137519 0.03729596 0.04182066 0.05646337\n",
      " 0.06620523 0.04391842 0.06545593 0.05148878 0.03851289 0.05030075\n",
      " 0.04019183 0.02898778 0.03112939 0.03026803 0.03352807 0.0382111\n",
      " 0.05236023 0.03834827 0.04458873 0.04169628 0.0663931  0.02519309\n",
      " 0.04279018 0.0385089  0.03664533 0.0321862  0.02528802 0.04460475\n",
      " 0.03408706 0.04116684 0.04601144 0.0435767  0.03859612 0.03903696\n",
      " 0.02391195 0.0505682  0.0512873  0.0330982  0.06486747 0.02889534\n",
      " 0.03535563 0.0380848  0.02562873 0.03160256 0.0325998  0.02826644\n",
      " 0.0353482  0.02990199 0.05384457 0.04153486 0.02742549 0.0278414\n",
      " 0.02958745 0.03724755 0.0288555  0.03138747 0.04327184 0.0467286\n",
      " 0.03804098 0.03297112 0.03188945 0.03687434 0.03780788 0.03609161\n",
      " 0.05044796 0.05129007 0.0431088  0.04453605 0.04092963 0.0339185\n",
      " 0.02882123 0.03078705 0.04194809 0.03348169 0.03360666 0.03678447\n",
      " 0.03519758 0.03998856 0.03198236 0.03332074 0.03794843 0.04552899\n",
      " 0.04303342 0.05191052 0.03695342 0.03511988 0.02858249 0.05243777\n",
      " 0.03233143 0.03570433 0.02462402 0.03127873 0.02069497 0.03325945\n",
      " 0.04490858 0.04286699 0.03272315 0.03178526]\n",
      "Label: 5813\n",
      "\n",
      "Data: [0.00705638 0.0568871  0.06887748 0.05137975 0.02336911 0.0246189\n",
      " 0.04770999 0.02886974 0.01914381 0.02043916 0.02428861 0.02222634\n",
      " 0.0331763  0.0234704  0.0289396  0.02275557 0.02888534 0.03658754\n",
      " 0.0288858  0.01602173 0.01428506 0.01191837 0.01900578 0.01119455\n",
      " 0.02396716 0.01533995 0.03509241 0.03793993 0.03652006 0.01808296\n",
      " 0.02476185 0.01873543 0.01372165 0.0164758  0.01254278 0.01768865\n",
      " 0.0188063  0.01748579 0.02243445 0.01366124 0.01645221 0.01686173\n",
      " 0.01498682 0.01991323 0.01472457 0.01933386 0.02505225 0.01822292\n",
      " 0.02226469 0.02602654 0.01546556 0.01794177 0.01245661 0.01635558\n",
      " 0.00924433 0.01568158 0.01934912 0.01976707 0.01579754 0.01537587\n",
      " 0.01508237 0.01784765 0.01667868 0.01393093 0.0244078  0.01877873\n",
      " 0.01211982 0.01217804 0.01263615 0.02261245 0.02155993 0.02129547\n",
      " 0.01951835 0.02104639 0.01116573 0.01703655 0.01549913 0.01747021\n",
      " 0.01775302 0.01283734 0.01728327 0.02307386 0.01580949 0.02239192\n",
      " 0.0148742  0.02163786 0.02273178 0.01756923 0.02384529 0.02182463\n",
      " 0.02877752 0.02567285 0.01866598 0.01725611 0.01428833 0.01982291\n",
      " 0.0170571  0.01730895 0.01157813 0.01958721 0.00817727 0.01139841\n",
      " 0.03119769 0.01590087 0.0171948  0.01747746]\n",
      "Label: 4829\n",
      "\n",
      "Data: [0.01165334 0.08276701 0.06750643 0.07739541 0.04009812 0.04009084\n",
      " 0.08020691 0.04429261 0.02328026 0.03572282 0.03258938 0.03725903\n",
      " 0.04934386 0.03331759 0.05020781 0.04591052 0.04228785 0.04690661\n",
      " 0.04125666 0.02490748 0.03098549 0.02597195 0.03207667 0.02018491\n",
      " 0.04210903 0.02588681 0.05841263 0.04028207 0.04037594 0.02784021\n",
      " 0.04536861 0.02856857 0.02899021 0.02252435 0.01561661 0.03434419\n",
      " 0.02968348 0.03764446 0.03200798 0.02587829 0.03136976 0.02898673\n",
      " 0.03283133 0.03172663 0.02545219 0.04185075 0.04063501 0.02952344\n",
      " 0.04249074 0.03096012 0.02274523 0.02123191 0.01808792 0.02150442\n",
      " 0.01783574 0.02187025 0.03134706 0.04009026 0.02624759 0.02862441\n",
      " 0.02338376 0.0333357  0.03498901 0.02243865 0.03169831 0.03333645\n",
      " 0.0219631  0.02490797 0.02244938 0.03081924 0.03719376 0.03397653\n",
      " 0.04284034 0.02909373 0.02132199 0.032998   0.0277314  0.02446872\n",
      " 0.02722052 0.02422808 0.02520311 0.04385796 0.02546757 0.0352197\n",
      " 0.02708407 0.027829   0.0285163  0.03449551 0.02773317 0.04092373\n",
      " 0.0428328  0.03905019 0.02932951 0.03176288 0.02256474 0.02858761\n",
      " 0.02135373 0.02327974 0.02181562 0.02775039 0.01644311 0.02695323\n",
      " 0.05923267 0.03628633 0.02303622 0.02374158]\n",
      "Label: 4829\n",
      "\n",
      "Data: [0.02680807 0.13183537 0.1079291  0.05195029 0.08355381 0.05029588\n",
      " 0.05733749 0.05519897 0.05141121 0.0507214  0.04136157 0.06562535\n",
      " 0.05115346 0.04259542 0.0543808  0.0553691  0.05112524 0.07715598\n",
      " 0.03808437 0.03331672 0.02993143 0.03364801 0.02925015 0.03781343\n",
      " 0.04597963 0.04862962 0.03313056 0.04371133 0.05374585 0.02992559\n",
      " 0.03167719 0.03626962 0.04721454 0.02508959 0.03809059 0.0460701\n",
      " 0.03860448 0.04518213 0.04444891 0.06036614 0.03451704 0.04056021\n",
      " 0.03125497 0.05379854 0.04519557 0.03440996 0.05023735 0.03382725\n",
      " 0.04323252 0.04773497 0.01842218 0.02861873 0.03287625 0.03144191\n",
      " 0.03886116 0.03191936 0.05593029 0.04260055 0.02797101 0.02492396\n",
      " 0.04578113 0.04460348 0.02940982 0.03720227 0.0427786  0.04684534\n",
      " 0.03301987 0.04173209 0.04029419 0.0321855  0.04632407 0.03876747\n",
      " 0.05118013 0.04426266 0.03082928 0.05571868 0.02992041 0.04296084\n",
      " 0.04476075 0.02248802 0.03165882 0.03647363 0.0316336  0.03765145\n",
      " 0.03529583 0.04368064 0.04155801 0.03282135 0.03768757 0.04264578\n",
      " 0.04405401 0.04581837 0.04481127 0.03301961 0.03363433 0.03677151\n",
      " 0.04557402 0.05360108 0.03848273 0.04233945 0.02990912 0.03374077\n",
      " 0.0619785  0.04189658 0.03143278 0.02990006]\n",
      "Label: 5411\n",
      "\n",
      "Data: [0.02784297 0.09433622 0.12299928 0.11734697 0.07057055 0.08499696\n",
      " 0.05548849 0.06171857 0.06546141 0.07480467 0.04675417 0.06718592\n",
      " 0.0506525  0.08437166 0.0571393  0.04062105 0.06027517 0.0731113\n",
      " 0.05232119 0.03499524 0.03198775 0.04583767 0.03111552 0.03619337\n",
      " 0.04171679 0.04004957 0.05090933 0.03577105 0.07840537 0.04018389\n",
      " 0.03965031 0.03298193 0.05607482 0.07067839 0.03578575 0.06424535\n",
      " 0.0504594  0.05756965 0.07415788 0.04549564 0.02735361 0.05025138\n",
      " 0.0288551  0.04452519 0.04166411 0.07001366 0.06059682 0.03679468\n",
      " 0.04683642 0.07473841 0.034603   0.03708362 0.0338839  0.03296012\n",
      " 0.05676566 0.05103403 0.0431719  0.05234646 0.04975031 0.04585323\n",
      " 0.06612867 0.03347662 0.02443473 0.04643882 0.0311693  0.03626302\n",
      " 0.04327501 0.0369585  0.03570343 0.0508695  0.06594644 0.03377527\n",
      " 0.04613476 0.06596687 0.05355699 0.04357803 0.04696482 0.03287955\n",
      " 0.05039708 0.02998847 0.03880779 0.04339228 0.03327549 0.04859702\n",
      " 0.0330711  0.04675548 0.06233044 0.03644911 0.06080441 0.05027017\n",
      " 0.05154459 0.06994895 0.04028897 0.04494589 0.03830404 0.07469176\n",
      " 0.04779257 0.04478848 0.04240021 0.03556825 0.0254833  0.04987571\n",
      " 0.04125886 0.0299908  0.04509287 0.0363997 ]\n",
      "Label: 5411\n",
      "\n",
      "Data: [0.01295887 0.08464953 0.04956545 0.03982802 0.0479298  0.04416801\n",
      " 0.02787159 0.04332227 0.04212861 0.04461519 0.02540494 0.02659447\n",
      " 0.03620916 0.02497542 0.03605815 0.04313716 0.02890871 0.03265698\n",
      " 0.02409595 0.02382249 0.01832816 0.02439845 0.0209715  0.02968974\n",
      " 0.04155435 0.02557893 0.01612165 0.02027201 0.03759615 0.01498424\n",
      " 0.02013833 0.01773005 0.02687879 0.01411919 0.01488284 0.0502729\n",
      " 0.0390968  0.03130853 0.02636974 0.03804295 0.01532035 0.01952779\n",
      " 0.02298068 0.02152054 0.02812751 0.02890377 0.03202295 0.02393867\n",
      " 0.02384135 0.02236312 0.01381372 0.01635506 0.01906364 0.01679554\n",
      " 0.027991   0.0197265  0.02615394 0.03035441 0.01826793 0.01517287\n",
      " 0.02768223 0.02418541 0.01394718 0.01636631 0.02246973 0.02447225\n",
      " 0.01729332 0.02853283 0.01692756 0.02783567 0.02199355 0.02605684\n",
      " 0.02391888 0.02455646 0.01514677 0.03438493 0.02610561 0.02173792\n",
      " 0.0345542  0.01913939 0.01932567 0.02657274 0.02111436 0.02369273\n",
      " 0.01921292 0.03973193 0.01859434 0.01841104 0.02659502 0.03128414\n",
      " 0.02525142 0.0243714  0.02682271 0.02996511 0.02724026 0.03041658\n",
      " 0.01714666 0.02889734 0.01813329 0.01522817 0.01410901 0.02330047\n",
      " 0.03476403 0.029473   0.01753327 0.0182149 ]\n",
      "Label: 6513\n",
      "\n",
      "Data: [0.02282826 0.11173883 0.11330681 0.07380886 0.06116771 0.06909705\n",
      " 0.06464373 0.06496597 0.06055197 0.0500528  0.04205237 0.0711019\n",
      " 0.05904551 0.04715304 0.06489719 0.06246046 0.05266951 0.06750341\n",
      " 0.0423225  0.03891337 0.03547158 0.04132053 0.03308228 0.04272813\n",
      " 0.05262888 0.04502542 0.04256053 0.04254332 0.06395303 0.03265248\n",
      " 0.03761979 0.03880375 0.04361591 0.03411616 0.0348778  0.05199256\n",
      " 0.04531335 0.04732398 0.04785334 0.05514443 0.03320356 0.03911731\n",
      " 0.0279848  0.04463857 0.05063279 0.0401601  0.05496213 0.03871279\n",
      " 0.0476516  0.04676712 0.02510466 0.03638105 0.03214385 0.03379907\n",
      " 0.04410239 0.03550844 0.05118464 0.04526541 0.03214644 0.02946721\n",
      " 0.04082039 0.04172967 0.0269169  0.03875809 0.0417772  0.05363606\n",
      " 0.03625003 0.04048146 0.03625669 0.04233965 0.04526165 0.03619169\n",
      " 0.04804543 0.04831175 0.03619682 0.04829059 0.04169197 0.03834543\n",
      " 0.04909223 0.03157709 0.0415445  0.04641903 0.03796016 0.04098581\n",
      " 0.03804507 0.05034446 0.03712    0.04077322 0.05778356 0.05148906\n",
      " 0.0497337  0.05137092 0.04210361 0.04757525 0.03446488 0.05273531\n",
      " 0.0443654  0.05115468 0.04034851 0.03872788 0.0291358  0.04679517\n",
      " 0.05432942 0.0521496  0.03095464 0.03752719]\n",
      "Label: 6513\n",
      "\n",
      "Data: [0.03880085 0.13898507 0.14938907 0.09867208 0.06634812 0.0728821\n",
      " 0.0851612  0.07068039 0.06395293 0.09344199 0.06668182 0.06840047\n",
      " 0.07230964 0.07053871 0.08944068 0.08367453 0.08923807 0.06054892\n",
      " 0.06965264 0.05853593 0.04368068 0.05663185 0.06712522 0.05791255\n",
      " 0.06076971 0.05692475 0.09479013 0.05826402 0.07616012 0.05064378\n",
      " 0.0571033  0.05071549 0.06685868 0.04466146 0.0582509  0.05712138\n",
      " 0.06904733 0.07258656 0.06133023 0.06612339 0.04119    0.0565868\n",
      " 0.05719333 0.07752521 0.06553765 0.05583705 0.07204027 0.0513396\n",
      " 0.07088281 0.07086191 0.04585778 0.04419296 0.0457043  0.05624795\n",
      " 0.05635826 0.04750777 0.06682774 0.07596778 0.04786273 0.05692277\n",
      " 0.04682946 0.0699598  0.05031891 0.05115062 0.07216599 0.06470557\n",
      " 0.05967183 0.04937126 0.04474387 0.05702402 0.04808054 0.07101861\n",
      " 0.06411095 0.07239158 0.05274967 0.06347472 0.07129748 0.04656438\n",
      " 0.05407923 0.04340836 0.06201996 0.07045514 0.05593175 0.05342219\n",
      " 0.05141864 0.05900444 0.06490883 0.0532282  0.07304146 0.06382258\n",
      " 0.06371912 0.08326575 0.06894474 0.07672906 0.04491561 0.06969147\n",
      " 0.06840665 0.06846336 0.06006578 0.06917851 0.04948272 0.06340148\n",
      " 0.10208499 0.06462661 0.06577053 0.04017052]\n",
      "Label: 4121\n",
      "\n",
      "Data: [0.02099457 0.11415129 0.11674999 0.07247335 0.05429433 0.05687486\n",
      " 0.06575379 0.05482042 0.0650209  0.05900754 0.05366463 0.05746532\n",
      " 0.04673582 0.05800475 0.05312042 0.05276277 0.06335375 0.06714286\n",
      " 0.03976976 0.03403967 0.02791073 0.0304534  0.02688217 0.04347281\n",
      " 0.04595643 0.0341128  0.0449551  0.03780083 0.05691392 0.03953654\n",
      " 0.03940616 0.02667908 0.03985387 0.02661101 0.0305277  0.04758513\n",
      " 0.04748733 0.04720387 0.05313053 0.0411461  0.02754317 0.03500026\n",
      " 0.02838891 0.05120615 0.04665952 0.05837448 0.04975554 0.03239515\n",
      " 0.04248539 0.05305359 0.03058117 0.03369164 0.03657478 0.0246175\n",
      " 0.04626558 0.03818616 0.04631998 0.04645732 0.03710245 0.04354226\n",
      " 0.04465944 0.03581155 0.02344077 0.03785226 0.04268147 0.03404813\n",
      " 0.03884984 0.02860155 0.0445656  0.04312418 0.04772425 0.04179354\n",
      " 0.04992037 0.05731785 0.03877963 0.04986444 0.0376044  0.0385154\n",
      " 0.03658695 0.02824263 0.0416087  0.03412759 0.02848747 0.03826389\n",
      " 0.0314477  0.050361   0.04500969 0.04562705 0.04539346 0.0500838\n",
      " 0.03804354 0.04942978 0.04291582 0.04258878 0.04592745 0.04757362\n",
      " 0.04659038 0.05286556 0.02742147 0.03382153 0.02630506 0.04143237\n",
      " 0.04401993 0.04008285 0.03274217 0.03306654]\n",
      "Label: 4121\n",
      "\n",
      "Data: [0.02000819 0.12088046 0.10805719 0.06473317 0.05914655 0.05040608\n",
      " 0.05903133 0.04719263 0.05192048 0.05849158 0.03769273 0.04794334\n",
      " 0.04637102 0.04024367 0.04383507 0.04680955 0.05345015 0.06346446\n",
      " 0.04040258 0.03317596 0.02443008 0.03126781 0.02634971 0.02726982\n",
      " 0.04319836 0.03641153 0.03416933 0.04845157 0.04942739 0.02940976\n",
      " 0.03271333 0.0267595  0.03813557 0.02648036 0.03162732 0.04259093\n",
      " 0.0413384  0.04165902 0.04174654 0.04541368 0.02693353 0.0351626\n",
      " 0.02573197 0.04109921 0.03553804 0.03635392 0.0408339  0.03242929\n",
      " 0.04089655 0.04502207 0.02482854 0.03600604 0.02421835 0.02989426\n",
      " 0.02934874 0.03125752 0.0425488  0.03897496 0.0269658  0.02382238\n",
      " 0.03807136 0.03849842 0.02234481 0.02962423 0.03959135 0.03915835\n",
      " 0.03275421 0.03300484 0.03265109 0.03530961 0.0376076  0.03336133\n",
      " 0.04358243 0.03848241 0.02384078 0.04197466 0.0335437  0.03798483\n",
      " 0.04036303 0.02380858 0.03287786 0.03712588 0.02962103 0.03567718\n",
      " 0.03090988 0.03948231 0.03821566 0.03378372 0.03984334 0.03786819\n",
      " 0.03938609 0.03973682 0.03432289 0.0375199  0.03477469 0.04048957\n",
      " 0.0337058  0.0352919  0.03180052 0.03619952 0.0207688  0.03619929\n",
      " 0.0478382  0.03849119 0.02829423 0.03020417]\n",
      "Label: 5732\n",
      "\n",
      "Data: [0.00877492 0.06911708 0.06391908 0.05320181 0.03114769 0.03316374\n",
      " 0.04081512 0.03458077 0.02927775 0.03364568 0.01981254 0.0248868\n",
      " 0.03026556 0.02236565 0.03272788 0.02754263 0.02553663 0.03562244\n",
      " 0.02565892 0.01943108 0.0174974  0.01796732 0.01632832 0.01649053\n",
      " 0.02926628 0.01535398 0.02640149 0.02789554 0.02971953 0.01576471\n",
      " 0.02401201 0.01471652 0.0210746  0.01553716 0.01109181 0.02679664\n",
      " 0.02358563 0.0261475  0.02633495 0.02351019 0.0177763  0.01608299\n",
      " 0.01634667 0.01920996 0.01978761 0.02784246 0.02859163 0.01861465\n",
      " 0.02291789 0.02320893 0.01566809 0.02017693 0.01057176 0.01447754\n",
      " 0.01553059 0.01552463 0.02287009 0.02527805 0.01658568 0.01453257\n",
      " 0.02016688 0.02167293 0.01343629 0.01507732 0.01990232 0.02310302\n",
      " 0.0159402  0.01946472 0.01443031 0.0205808  0.02209182 0.0213263\n",
      " 0.02381049 0.01835242 0.01310816 0.02201438 0.01973478 0.01807698\n",
      " 0.02021336 0.01429677 0.02024372 0.0257403  0.01499074 0.0227834\n",
      " 0.01719255 0.02229161 0.01843035 0.02232632 0.01993791 0.02252791\n",
      " 0.02740309 0.02653378 0.01732714 0.02205295 0.02129665 0.02293386\n",
      " 0.0150579  0.01548198 0.01365192 0.0172359  0.00986117 0.01980661\n",
      " 0.02768261 0.0204712  0.01581918 0.01750178]\n",
      "Label: 5732\n",
      "\n",
      "Data: [0.02018986 0.12925248 0.0760515  0.08653779 0.04361733 0.05498056\n",
      " 0.05782364 0.05041527 0.04579526 0.07949045 0.04348436 0.03787456\n",
      " 0.0370262  0.04993058 0.04400872 0.04863155 0.07212423 0.053875\n",
      " 0.04149391 0.02970805 0.03647496 0.02927947 0.03381272 0.03774279\n",
      " 0.04830684 0.02928496 0.04815448 0.03780342 0.05164365 0.03311264\n",
      " 0.04024341 0.02142303 0.04747732 0.01922701 0.030847   0.04489867\n",
      " 0.0554827  0.05631986 0.0271209  0.04236012 0.02052837 0.02967249\n",
      " 0.0488853  0.03208242 0.03077973 0.06114075 0.04047148 0.04081201\n",
      " 0.05756435 0.0437207  0.0297194  0.02226051 0.02424565 0.02282178\n",
      " 0.02911994 0.0268084  0.03145529 0.05759118 0.02893453 0.03771805\n",
      " 0.03270728 0.04183168 0.02320043 0.03381217 0.04234769 0.03113667\n",
      " 0.0317124  0.03845048 0.02963699 0.03392767 0.03842711 0.03943802\n",
      " 0.04861036 0.03625009 0.0230085  0.0459944  0.04259805 0.03177506\n",
      " 0.034532   0.02341704 0.02871619 0.05141006 0.02962395 0.03737018\n",
      " 0.03040125 0.04496519 0.0377444  0.02671053 0.03004652 0.05830057\n",
      " 0.02757747 0.04346971 0.03511579 0.04901605 0.04698949 0.04042642\n",
      " 0.03410188 0.0296135  0.03196287 0.03153471 0.0284291  0.03640979\n",
      " 0.07043019 0.05419023 0.031269   0.02012137]\n",
      "Label: 6012\n",
      "\n",
      "Data: [0.02128791 0.12414159 0.08092195 0.07053752 0.0484553  0.05189345\n",
      " 0.07540325 0.04431329 0.04756492 0.04061034 0.06775127 0.07280628\n",
      " 0.03169142 0.06451413 0.06868841 0.03288228 0.05197536 0.06877553\n",
      " 0.04353387 0.03659914 0.02504333 0.03054895 0.02464731 0.02127411\n",
      " 0.03751338 0.01695077 0.05266279 0.03633732 0.04626985 0.03054666\n",
      " 0.03122217 0.02633475 0.03168118 0.0296545  0.02262755 0.03448295\n",
      " 0.02885818 0.05046559 0.04597942 0.02875889 0.02392469 0.03045329\n",
      " 0.02447203 0.04155967 0.03091264 0.04254338 0.04304678 0.02500052\n",
      " 0.02979243 0.04595841 0.02177949 0.02396565 0.02617979 0.02848179\n",
      " 0.03037036 0.03752358 0.03016672 0.04738106 0.02653148 0.03282941\n",
      " 0.03538609 0.03423392 0.02112196 0.0452799  0.03787617 0.04356081\n",
      " 0.02935493 0.02189846 0.03015288 0.03220087 0.04945246 0.03563311\n",
      " 0.04548596 0.04266235 0.02874013 0.04035589 0.02652011 0.02587873\n",
      " 0.02961278 0.01918187 0.02781751 0.03851591 0.01984719 0.03385636\n",
      " 0.02947665 0.04206695 0.06130248 0.04439956 0.05958642 0.04714787\n",
      " 0.04162471 0.04837729 0.02516169 0.04379628 0.0336999  0.03212506\n",
      " 0.0579864  0.04216738 0.03289136 0.02953997 0.020014   0.05110881\n",
      " 0.04265894 0.03796362 0.03491437 0.02718964]\n",
      "Label: 6012\n",
      "\n",
      "Data: [0.02578827 0.1446947  0.14246316 0.11535279 0.05259495 0.07890671\n",
      " 0.09146063 0.04514051 0.05399081 0.08987343 0.07798836 0.05934818\n",
      " 0.07015908 0.06314529 0.05850327 0.04935811 0.08652164 0.07879952\n",
      " 0.08207798 0.04825824 0.03488893 0.03903507 0.04120938 0.03857916\n",
      " 0.07354411 0.04380157 0.04863643 0.07102683 0.11191157 0.05259307\n",
      " 0.07794289 0.05182734 0.04665662 0.04014065 0.03449644 0.07375763\n",
      " 0.07401958 0.0619656  0.06077971 0.05724227 0.03681884 0.05605127\n",
      " 0.05177145 0.0647096  0.04997241 0.05454395 0.05339715 0.05161546\n",
      " 0.06096636 0.04724523 0.0527489  0.05072516 0.04761063 0.04599881\n",
      " 0.04089715 0.05541546 0.03774821 0.05840003 0.0413537  0.04268799\n",
      " 0.07344209 0.05672712 0.04172702 0.03347781 0.0663403  0.05091984\n",
      " 0.03604942 0.03777958 0.03895174 0.06779487 0.05228782 0.07078023\n",
      " 0.08045083 0.04724805 0.0352543  0.05398384 0.05749943 0.05203964\n",
      " 0.04852898 0.05802787 0.03714916 0.05756346 0.04658456 0.05592577\n",
      " 0.04794022 0.0799897  0.06630181 0.04976054 0.0687605  0.05404108\n",
      " 0.04747261 0.06960858 0.04903728 0.06002797 0.04049721 0.06046318\n",
      " 0.03226594 0.04184395 0.0493166  0.03700103 0.02294005 0.0375788\n",
      " 0.07936013 0.05740696 0.04141246 0.04769251]\n",
      "Label: 6011\n",
      "\n",
      "Data: [0.01618838 0.11745185 0.10044728 0.055215   0.05100882 0.04278669\n",
      " 0.052735   0.06032307 0.04442208 0.02610855 0.08277325 0.06787731\n",
      " 0.03354812 0.03981597 0.06840187 0.0295853  0.03565723 0.05666117\n",
      " 0.03230145 0.02247161 0.01663617 0.03079972 0.02257123 0.01924665\n",
      " 0.04621687 0.02564827 0.02995947 0.03643675 0.04379828 0.02567355\n",
      " 0.01852209 0.02437814 0.02054517 0.03069459 0.0197105  0.02441533\n",
      " 0.01774336 0.03093614 0.04217365 0.02878403 0.03097707 0.0252843\n",
      " 0.01344882 0.04730131 0.03798226 0.02411245 0.05061277 0.0150214\n",
      " 0.02117646 0.03426421 0.01633773 0.02680201 0.02392945 0.03195551\n",
      " 0.03838415 0.03943785 0.0282538  0.0412704  0.02541032 0.02495715\n",
      " 0.02662468 0.02863563 0.01704077 0.03375715 0.03578613 0.04000024\n",
      " 0.03102543 0.01848189 0.02498605 0.02287869 0.03989172 0.03801237\n",
      " 0.03515657 0.06046636 0.03332324 0.04130588 0.02392009 0.02064984\n",
      " 0.02472561 0.01229179 0.02725215 0.02425615 0.01644659 0.03389492\n",
      " 0.02157038 0.04052667 0.05671084 0.03384287 0.05994924 0.03062983\n",
      " 0.04062178 0.03236119 0.02538577 0.02482273 0.02207864 0.03432665\n",
      " 0.05347055 0.06148295 0.02381626 0.04238801 0.01669954 0.03381532\n",
      " 0.02470323 0.02972344 0.0259228  0.02707076]\n",
      "Label: 6011\n",
      "\n",
      "Data: [0.01183222 0.05922027 0.05371509 0.047172   0.06422119 0.03451478\n",
      " 0.04360375 0.03891248 0.03748141 0.0311276  0.02613164 0.03269854\n",
      " 0.05178023 0.02628344 0.03714436 0.0369353  0.03192857 0.0333563\n",
      " 0.02972564 0.02374534 0.01278602 0.01536298 0.02003682 0.01396248\n",
      " 0.03295091 0.02598655 0.03009496 0.0326028  0.0458259  0.01179359\n",
      " 0.01705081 0.02827393 0.02209111 0.02219854 0.01517668 0.04596551\n",
      " 0.02724179 0.03129236 0.02634342 0.02555    0.01672678 0.0211099\n",
      " 0.01106051 0.03127735 0.0276925  0.01812388 0.0230149  0.02183876\n",
      " 0.01583042 0.03416074 0.01332466 0.02063294 0.01507625 0.02460981\n",
      " 0.02041654 0.01856937 0.05341826 0.03597004 0.01223937 0.01288912\n",
      " 0.01520948 0.01976532 0.01458006 0.01880945 0.02709366 0.02695633\n",
      " 0.021297   0.01763029 0.01326113 0.02500569 0.02020281 0.02248835\n",
      " 0.02145483 0.02421395 0.01568195 0.0392748  0.02132632 0.02195783\n",
      " 0.01777499 0.01458637 0.02003376 0.02067363 0.0187621  0.01829134\n",
      " 0.03137182 0.02516563 0.02013395 0.01812156 0.02680302 0.02635991\n",
      " 0.03045637 0.02863347 0.02131659 0.02870587 0.01511537 0.0285992\n",
      " 0.02357126 0.02884822 0.01640235 0.02201661 0.01371993 0.02106244\n",
      " 0.03336618 0.02809805 0.02245958 0.01872936]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.02500727 0.12232015 0.13275021 0.05787354 0.05930287 0.05049673\n",
      " 0.05359804 0.0624493  0.0694597  0.05762603 0.05184028 0.04890787\n",
      " 0.04423672 0.04979183 0.06233599 0.04938298 0.05364863 0.05531445\n",
      " 0.04520271 0.03002098 0.02592354 0.03836439 0.02942521 0.03926889\n",
      " 0.04058079 0.03265035 0.0452794  0.03968683 0.0511081  0.03234864\n",
      " 0.03110563 0.02416661 0.04189366 0.0296355  0.03433208 0.04176047\n",
      " 0.0474972  0.04690448 0.05068322 0.0458515  0.02924721 0.03309613\n",
      " 0.02926258 0.05129938 0.03876221 0.04857439 0.05109425 0.02534124\n",
      " 0.0328036  0.05299474 0.02782208 0.03848933 0.03137411 0.03410261\n",
      " 0.03858106 0.03901887 0.04633263 0.0392124  0.04099079 0.03361835\n",
      " 0.04158743 0.04236712 0.0238901  0.03800347 0.04061805 0.03855114\n",
      " 0.04253608 0.03424619 0.03927165 0.03973507 0.03995252 0.03858808\n",
      " 0.03791527 0.0562622  0.03701987 0.04208725 0.03486584 0.03552515\n",
      " 0.0517611  0.02293223 0.04423308 0.03270682 0.02639483 0.04989932\n",
      " 0.0266872  0.04356264 0.04805065 0.0429723  0.05058535 0.04280697\n",
      " 0.04714411 0.03836126 0.03942179 0.04067486 0.04170672 0.04889599\n",
      " 0.0493767  0.04413434 0.02756057 0.03573263 0.02577518 0.04795468\n",
      " 0.03642772 0.03115349 0.03842882 0.03570508]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.01737251 0.08956482 0.07569178 0.07118706 0.04954766 0.06018765\n",
      " 0.06282185 0.03597925 0.0419661  0.05561944 0.02958171 0.04655737\n",
      " 0.04140504 0.06067515 0.0493593  0.04831244 0.04843091 0.04659304\n",
      " 0.04667731 0.04379842 0.0253968  0.02318083 0.03159453 0.03280476\n",
      " 0.03186804 0.01931555 0.06063562 0.04140958 0.04587143 0.02155268\n",
      " 0.05066829 0.02787093 0.0476717  0.02782902 0.02424457 0.05365099\n",
      " 0.04284177 0.0614528  0.04660374 0.04277688 0.02071612 0.04297609\n",
      " 0.02740344 0.04659081 0.03714782 0.04143798 0.04794506 0.03007974\n",
      " 0.04110094 0.062045   0.02307735 0.02925867 0.02106038 0.02539035\n",
      " 0.02204641 0.01837053 0.05343807 0.05148881 0.02298325 0.02961493\n",
      " 0.04446259 0.04278649 0.0248433  0.03215313 0.02881982 0.03428448\n",
      " 0.03436483 0.03089631 0.02962274 0.0357536  0.03497743 0.02712822\n",
      " 0.05220728 0.03065685 0.03660552 0.03114691 0.03448231 0.0333145\n",
      " 0.02652576 0.02744342 0.03493958 0.03315469 0.0241368  0.02300501\n",
      " 0.0439268  0.02932485 0.0321087  0.03520655 0.02447914 0.04310815\n",
      " 0.03446916 0.05476968 0.03619471 0.03757276 0.03539517 0.03369194\n",
      " 0.03483044 0.02119162 0.03159562 0.02185677 0.02350656 0.04442386\n",
      " 0.0558928  0.03426044 0.03944347 0.02611139]\n",
      "Label: 6300\n",
      "\n",
      "Data: [0.02605404 0.10455466 0.08879668 0.09809276 0.06088309 0.06992092\n",
      " 0.07519775 0.04994221 0.0537593  0.06796642 0.03257295 0.07224521\n",
      " 0.04263031 0.06521933 0.06090514 0.04895272 0.06465549 0.06779981\n",
      " 0.04570844 0.05368884 0.02423145 0.032434   0.03446194 0.03508129\n",
      " 0.04544819 0.03271314 0.06064237 0.05444503 0.05879159 0.03797452\n",
      " 0.05570201 0.04135897 0.05016187 0.03955477 0.03613723 0.05240747\n",
      " 0.0425556  0.06488256 0.05295154 0.05387644 0.02976958 0.04836932\n",
      " 0.02394429 0.05894787 0.05288645 0.03882428 0.05124404 0.04099584\n",
      " 0.06263062 0.06703012 0.02911697 0.04207592 0.02294123 0.03603095\n",
      " 0.04404442 0.02775198 0.07173149 0.08600213 0.02227964 0.03341238\n",
      " 0.05106532 0.03638101 0.02579221 0.04309499 0.03726872 0.04024793\n",
      " 0.05028789 0.03011517 0.03722839 0.03645301 0.04129686 0.03410906\n",
      " 0.07248303 0.04340157 0.04020937 0.03908562 0.05046503 0.04432881\n",
      " 0.03125381 0.02911107 0.04654483 0.04595593 0.03314174 0.02724176\n",
      " 0.06748264 0.02989893 0.03667136 0.04454737 0.03469529 0.03992745\n",
      " 0.03558251 0.05683881 0.03732291 0.04742044 0.03344491 0.04301543\n",
      " 0.04243733 0.0345471  0.0476546  0.03916245 0.03034836 0.05553967\n",
      " 0.06373581 0.05420851 0.03199435 0.03608848]\n",
      "Label: 6300\n",
      "\n",
      "Data: [0.01464568 0.08398888 0.09633039 0.06865352 0.04452221 0.0400454\n",
      " 0.08039908 0.04421361 0.05102853 0.04181628 0.04066907 0.04950631\n",
      " 0.0386282  0.05339711 0.0685729  0.04283631 0.02440389 0.05167757\n",
      " 0.04537025 0.02373609 0.03655075 0.02574731 0.02758479 0.02872464\n",
      " 0.02454722 0.02068372 0.05861769 0.02256021 0.04207902 0.01795886\n",
      " 0.04381386 0.02315705 0.03650156 0.02644818 0.03232056 0.03850274\n",
      " 0.0234021  0.05161397 0.0511049  0.03658389 0.02982596 0.04367815\n",
      " 0.02204359 0.05003843 0.03240827 0.03617801 0.05679838 0.02534049\n",
      " 0.03025833 0.03466834 0.02802513 0.02843168 0.02369188 0.02297701\n",
      " 0.02777141 0.02435636 0.05400611 0.03336043 0.02326718 0.02483261\n",
      " 0.02698076 0.02859346 0.02248264 0.03950869 0.043262   0.05090016\n",
      " 0.03645277 0.05056628 0.03298032 0.01715961 0.02928227 0.0305238\n",
      " 0.04522519 0.0298095  0.04489994 0.04016552 0.02885953 0.03078469\n",
      " 0.02129151 0.01630243 0.05167392 0.03370989 0.03015187 0.03448605\n",
      " 0.02498758 0.03387874 0.0335504  0.03462553 0.0339757  0.04224167\n",
      " 0.02824915 0.05772976 0.04148792 0.02604855 0.02612553 0.03488909\n",
      " 0.04461414 0.02790009 0.02466332 0.03123524 0.02126378 0.05063648\n",
      " 0.04708155 0.03961339 0.03202045 0.02677439]\n",
      "Label: 4900\n",
      "\n",
      "Data: [0.01270366 0.08953449 0.06756383 0.04762739 0.04040527 0.03725753\n",
      " 0.0563935  0.03663556 0.03417268 0.03083934 0.03560284 0.04784256\n",
      " 0.04755294 0.04253009 0.03572685 0.04354762 0.04389491 0.05158839\n",
      " 0.03114361 0.0292185  0.02269615 0.02200726 0.02225544 0.02944045\n",
      " 0.03142218 0.02213985 0.03283708 0.03250792 0.03533814 0.01749498\n",
      " 0.02836022 0.02011451 0.03034206 0.02078854 0.0171035  0.04463468\n",
      " 0.03299313 0.03834151 0.03447196 0.02732135 0.01724472 0.03461954\n",
      " 0.02507942 0.02739123 0.02612436 0.02912884 0.03264377 0.02042749\n",
      " 0.02968022 0.04164254 0.0130947  0.02017725 0.01932862 0.01565329\n",
      " 0.01567306 0.01997503 0.02916792 0.02927768 0.019688   0.0233468\n",
      " 0.03789027 0.03931436 0.02532296 0.02433189 0.03096293 0.02817846\n",
      " 0.0218714  0.02132245 0.03645714 0.04095649 0.02975683 0.02449976\n",
      " 0.03775867 0.03318813 0.02224233 0.03820946 0.0206405  0.02110979\n",
      " 0.02790618 0.02326205 0.02595011 0.02617719 0.01384503 0.02941884\n",
      " 0.03196742 0.03527012 0.03227168 0.03318542 0.03106858 0.04480984\n",
      " 0.03450078 0.0372126  0.02759953 0.02808612 0.03363085 0.03000131\n",
      " 0.03628474 0.02450982 0.02615037 0.01885004 0.01741427 0.03144353\n",
      " 0.0442623  0.03544831 0.0254113  0.01876338]\n",
      "Label: 4900\n",
      "\n",
      "Data: [0.00743518 0.07307309 0.11941196 0.06223315 0.02143802 0.0294471\n",
      " 0.03478251 0.02051952 0.03127226 0.04234912 0.03010016 0.03156749\n",
      " 0.01712609 0.02614005 0.02990471 0.02156726 0.03617949 0.030824\n",
      " 0.03363568 0.01781098 0.01140606 0.01462261 0.01236588 0.01949407\n",
      " 0.02472812 0.00959511 0.0223187  0.02147082 0.03601669 0.01844372\n",
      " 0.02392639 0.01635485 0.01868921 0.01331372 0.01286269 0.02064784\n",
      " 0.02612392 0.02479796 0.02848316 0.02094778 0.01446179 0.02368922\n",
      " 0.01362086 0.02811198 0.02310398 0.02047649 0.03231928 0.01346671\n",
      " 0.01787843 0.02194805 0.01616888 0.02655271 0.01320559 0.01441398\n",
      " 0.01646991 0.01706048 0.01676637 0.02574128 0.01790646 0.01627029\n",
      " 0.02687401 0.01926922 0.01160112 0.01728854 0.02571654 0.02028326\n",
      " 0.01534789 0.01344456 0.01617827 0.01880329 0.02194258 0.02137901\n",
      " 0.03447622 0.02106926 0.02216505 0.01820086 0.02407711 0.01729887\n",
      " 0.01605625 0.01286537 0.02202058 0.02218287 0.01334773 0.01876722\n",
      " 0.01618851 0.02851226 0.02799094 0.02390446 0.02723847 0.02663084\n",
      " 0.01879272 0.03461134 0.0172221  0.01840669 0.01621793 0.02498562\n",
      " 0.01777449 0.01467458 0.01906712 0.0151583  0.008005   0.02169599\n",
      " 0.01838113 0.01769963 0.01661475 0.01604031]\n",
      "Label: 5967\n",
      "\n",
      "Data: [0.01237921 0.07051388 0.10393105 0.06622908 0.04396881 0.04013063\n",
      " 0.0512564  0.03378081 0.03166495 0.04023666 0.03027876 0.03696538\n",
      " 0.05205546 0.03925037 0.04400631 0.038752   0.03493928 0.04273117\n",
      " 0.03540618 0.01911912 0.02056307 0.01913298 0.02011845 0.02487486\n",
      " 0.03452146 0.02896424 0.03488973 0.02753833 0.0598061  0.01807402\n",
      " 0.03316814 0.02886188 0.03113482 0.02454324 0.02130059 0.0365432\n",
      " 0.03336537 0.03424651 0.04388659 0.0308003  0.02413419 0.03186047\n",
      " 0.01964949 0.04070574 0.0326327  0.03196309 0.04230785 0.02035101\n",
      " 0.02589519 0.03084536 0.02100937 0.02180591 0.02944637 0.02203462\n",
      " 0.02630627 0.02662747 0.04079354 0.02635928 0.0246688  0.02300676\n",
      " 0.02894255 0.02586304 0.02338092 0.01962175 0.03055973 0.02954514\n",
      " 0.02641598 0.02469258 0.02215172 0.02938087 0.03187813 0.02928272\n",
      " 0.03774775 0.04103511 0.03129725 0.03934737 0.02527247 0.02922304\n",
      " 0.02723126 0.02482727 0.02686346 0.02421706 0.0266352  0.02979896\n",
      " 0.02141809 0.03008927 0.02753991 0.02458349 0.03027812 0.03222042\n",
      " 0.03314432 0.0400534  0.02951162 0.02508383 0.01918337 0.03906313\n",
      " 0.02024272 0.02756006 0.01895456 0.0201745  0.01275477 0.02142323\n",
      " 0.03467892 0.02131611 0.02997198 0.02194459]\n",
      "Label: 5967\n",
      "\n",
      "Data: [0.00702195 0.07201914 0.13511992 0.03876182 0.03216908 0.02601564\n",
      " 0.02482722 0.01351713 0.02369881 0.061503   0.01709316 0.0218965\n",
      " 0.01843433 0.02010109 0.01554879 0.03142546 0.06350818 0.02142037\n",
      " 0.02259829 0.01632887 0.00920579 0.01152429 0.01035481 0.01628269\n",
      " 0.02070423 0.01286658 0.02335771 0.01772467 0.02383446 0.01391225\n",
      " 0.01220574 0.01032072 0.02483316 0.00857219 0.01172394 0.02161756\n",
      " 0.03707959 0.02663381 0.02107946 0.02249569 0.00780035 0.0173369\n",
      " 0.01424869 0.02181905 0.0178769  0.02787821 0.01829002 0.01136922\n",
      " 0.01840624 0.0238124  0.01081433 0.01613376 0.00993427 0.01079295\n",
      " 0.01206301 0.0134532  0.01879827 0.02154252 0.0196223  0.01716154\n",
      " 0.01964313 0.02401065 0.01070506 0.01001528 0.01655849 0.01310355\n",
      " 0.0137972  0.01071406 0.01237942 0.02066131 0.02095303 0.01491229\n",
      " 0.02364318 0.02295437 0.01451212 0.02328129 0.01803283 0.01442367\n",
      " 0.01791792 0.01242973 0.01196728 0.01779955 0.01164375 0.0134036\n",
      " 0.01229792 0.01721724 0.01948878 0.01875599 0.01910522 0.02496323\n",
      " 0.02024459 0.02636587 0.01840086 0.02291429 0.01532099 0.0233697\n",
      " 0.01525148 0.0148076  0.01655353 0.01387871 0.00955217 0.01885786\n",
      " 0.02245288 0.01310958 0.01718983 0.00882438]\n",
      "Label: 6012\n",
      "\n",
      "Data: [0.01779018 0.11649779 0.11340074 0.06313707 0.04819858 0.05163623\n",
      " 0.05730763 0.04523606 0.03949951 0.05223857 0.04659358 0.06250119\n",
      " 0.04477693 0.04677188 0.04781947 0.06751536 0.08353125 0.05213406\n",
      " 0.03839417 0.03215058 0.02411268 0.0344722  0.03090588 0.03260729\n",
      " 0.04132795 0.03191177 0.04277553 0.03833115 0.04723749 0.02955523\n",
      " 0.03024086 0.0323391  0.03525788 0.02976769 0.03023374 0.04226377\n",
      " 0.05150982 0.04189492 0.03888946 0.03693772 0.02025684 0.03752712\n",
      " 0.02435674 0.04200679 0.03758371 0.04117105 0.04311207 0.02680732\n",
      " 0.04810828 0.04791926 0.02217757 0.0246496  0.02870217 0.03176279\n",
      " 0.02795508 0.03015886 0.03321863 0.0436225  0.03699801 0.0375952\n",
      " 0.03580205 0.04462116 0.02875493 0.03202029 0.03360579 0.03775605\n",
      " 0.02807455 0.02468259 0.02750557 0.04699429 0.04877019 0.0337658\n",
      " 0.04155555 0.05732986 0.03486386 0.04340277 0.03440139 0.02650913\n",
      " 0.04442816 0.02567324 0.03421856 0.04028106 0.03138696 0.02941031\n",
      " 0.02910894 0.04631675 0.04372615 0.03758977 0.05299482 0.05865941\n",
      " 0.04864903 0.04428333 0.03776167 0.04641612 0.03291139 0.04358876\n",
      " 0.04424289 0.04873987 0.0404558  0.03221815 0.02397928 0.04497583\n",
      " 0.05250396 0.03657597 0.03946505 0.02709082]\n",
      "Label: 6012\n",
      "\n",
      "Data: [0.01424211 0.12367926 0.03972859 0.03273226 0.03902152 0.0247825\n",
      " 0.02816525 0.02634496 0.0221873  0.03373898 0.02290396 0.02789525\n",
      " 0.01752293 0.02707952 0.0297003  0.02264525 0.03437986 0.04198104\n",
      " 0.01944932 0.01444868 0.00762912 0.01779207 0.01289339 0.01583524\n",
      " 0.02682016 0.02013938 0.01085727 0.02237397 0.03202291 0.01595935\n",
      " 0.01796908 0.01836334 0.02023617 0.01023218 0.019885   0.02337295\n",
      " 0.02878014 0.02506223 0.01902107 0.02836551 0.01361054 0.02276478\n",
      " 0.01615181 0.02928474 0.01915014 0.01771762 0.026545   0.01384194\n",
      " 0.0216219  0.02125075 0.00939614 0.01123015 0.02004526 0.01615302\n",
      " 0.01878132 0.01628839 0.021485   0.02694852 0.01206994 0.01099483\n",
      " 0.02783116 0.01783249 0.01378887 0.01795379 0.02243023 0.01555228\n",
      " 0.0184802  0.01438963 0.02007935 0.02078676 0.023711   0.01862421\n",
      " 0.03419781 0.03032563 0.01161993 0.02483221 0.01669706 0.02522741\n",
      " 0.03414341 0.01131829 0.01419933 0.01786244 0.01533774 0.01994646\n",
      " 0.01566472 0.02295997 0.02415217 0.01304063 0.01685723 0.02328197\n",
      " 0.01667876 0.01366904 0.01693888 0.02094739 0.0196999  0.017178\n",
      " 0.01414128 0.02059058 0.01529196 0.01209634 0.00880446 0.01774635\n",
      " 0.02724967 0.01861937 0.01367955 0.01372322]\n",
      "Label: 5712\n",
      "\n",
      "Data: [0.04827448 0.17023355 0.12490424 0.12681003 0.09429416 0.07982185\n",
      " 0.08115218 0.08337994 0.08767622 0.09962093 0.06213159 0.07390224\n",
      " 0.06987571 0.07488643 0.07500062 0.06271928 0.08704695 0.11177549\n",
      " 0.07598308 0.06152974 0.03793064 0.06364012 0.04733574 0.06707513\n",
      " 0.06749672 0.06285644 0.04952301 0.06965917 0.09205808 0.05678448\n",
      " 0.05808685 0.06418605 0.0650685  0.05379094 0.05191761 0.0832145\n",
      " 0.09186847 0.07166564 0.07371882 0.07029808 0.05086279 0.07105124\n",
      " 0.04847222 0.07404299 0.07718734 0.08174802 0.08684574 0.05828004\n",
      " 0.05628475 0.09257916 0.05052356 0.06335919 0.05281103 0.04389849\n",
      " 0.0680802  0.0473088  0.07169054 0.07593655 0.06154541 0.05375391\n",
      " 0.08304087 0.06233549 0.04805689 0.06231969 0.07695628 0.0524781\n",
      " 0.06035189 0.04619168 0.066119   0.08001398 0.07449528 0.06443026\n",
      " 0.08022373 0.07102962 0.05157616 0.07623212 0.0668399  0.06287777\n",
      " 0.06246553 0.04947318 0.06383492 0.06919869 0.0450224  0.05897789\n",
      " 0.05344111 0.08747383 0.08211986 0.05044398 0.05705425 0.07556646\n",
      " 0.06948646 0.08728749 0.06528372 0.07045355 0.08124486 0.06360746\n",
      " 0.05513514 0.06458402 0.04420054 0.05779611 0.0427718  0.05273886\n",
      " 0.06463797 0.04939446 0.05280316 0.04687382]\n",
      "Label: 5712\n",
      "\n",
      "Data: [0.02426575 0.08151461 0.15176123 0.12411849 0.07641847 0.06439207\n",
      " 0.06606495 0.06868053 0.05896221 0.07974447 0.04979073 0.06698955\n",
      " 0.07560381 0.05188299 0.06270194 0.06301855 0.06543329 0.06264435\n",
      " 0.06064344 0.03929418 0.02866243 0.04530806 0.03759495 0.03348316\n",
      " 0.05624228 0.05596055 0.05933235 0.04230385 0.07995042 0.04472973\n",
      " 0.03530175 0.05125374 0.0447881  0.0611445  0.03449742 0.05556965\n",
      " 0.05241343 0.04198586 0.05871129 0.03915004 0.03510791 0.04225885\n",
      " 0.02787495 0.05009582 0.0540182  0.04828853 0.0518367  0.04449594\n",
      " 0.0425563  0.06226369 0.03852207 0.04800137 0.03526904 0.04740044\n",
      " 0.05886675 0.04933614 0.05739374 0.05344264 0.04116236 0.04033924\n",
      " 0.03398238 0.03137919 0.02979212 0.04136284 0.04641774 0.04871104\n",
      " 0.04065754 0.03225079 0.02917539 0.04813002 0.05130706 0.05115573\n",
      " 0.04302881 0.06635474 0.04240783 0.05586665 0.05390723 0.03599463\n",
      " 0.0422831  0.03182866 0.05224816 0.05561369 0.04582394 0.04420618\n",
      " 0.04096354 0.05156124 0.05459803 0.04469753 0.07303202 0.05325994\n",
      " 0.06460419 0.08055073 0.04167588 0.05079    0.02774705 0.07884513\n",
      " 0.04221687 0.06462718 0.04312657 0.05710328 0.02748179 0.04036818\n",
      " 0.05130547 0.03812005 0.0455826  0.03877752]\n",
      "Label: 6211\n",
      "\n",
      "Data: [0.03195087 0.13635494 0.08801387 0.07269821 0.05342651 0.05306743\n",
      " 0.05095068 0.05735396 0.0616724  0.05093727 0.05819342 0.04971926\n",
      " 0.04129647 0.06079577 0.05844652 0.03289178 0.05204722 0.07631122\n",
      " 0.04834048 0.04973882 0.03060074 0.03718591 0.03628207 0.0472127\n",
      " 0.04455736 0.02441022 0.04377797 0.04402989 0.0605624  0.03759778\n",
      " 0.03300062 0.02892262 0.03779864 0.035786   0.0282007  0.06931661\n",
      " 0.04811361 0.05422403 0.05959458 0.03442507 0.02569562 0.03026812\n",
      " 0.04251234 0.035919   0.0337349  0.06478084 0.05037806 0.03130175\n",
      " 0.03575844 0.04078964 0.03248015 0.03090723 0.02918293 0.02585454\n",
      " 0.04144194 0.04351849 0.03699411 0.05452267 0.04278252 0.04932313\n",
      " 0.06161201 0.03772084 0.02930223 0.03125338 0.05484148 0.0331535\n",
      " 0.0301138  0.02935966 0.0411819  0.0520636  0.0373096  0.05019576\n",
      " 0.03788438 0.04996731 0.02852339 0.0515974  0.03438688 0.025328\n",
      " 0.03664563 0.02777451 0.03962267 0.05657248 0.02384675 0.04675685\n",
      " 0.03862832 0.05685953 0.05256693 0.03647266 0.06064396 0.03958963\n",
      " 0.04292061 0.05249708 0.04984361 0.04053189 0.0568972  0.04162993\n",
      " 0.06312472 0.04849377 0.0253157  0.03193644 0.02782042 0.04181637\n",
      " 0.0681295  0.03990007 0.03539913 0.03157613]\n",
      "Label: 6211\n",
      "\n",
      "Data: [0.00992708 0.05050386 0.21619517 0.0590748  0.04901637 0.03432149\n",
      " 0.05426443 0.03133396 0.05744188 0.05822292 0.04207274 0.05084227\n",
      " 0.03131181 0.03117876 0.03170358 0.04023102 0.04327545 0.03662093\n",
      " 0.06617913 0.03020889 0.01878546 0.02311786 0.01888926 0.02085727\n",
      " 0.02269318 0.01587664 0.05673826 0.02630822 0.0317743  0.03120851\n",
      " 0.02037309 0.01792172 0.03052905 0.02393778 0.01602244 0.03048206\n",
      " 0.03066656 0.02620118 0.05458858 0.0238314  0.02150344 0.03459258\n",
      " 0.02501503 0.0306144  0.02199904 0.02243241 0.03138895 0.02028852\n",
      " 0.01341046 0.04386164 0.01809069 0.05751386 0.01207195 0.0201037\n",
      " 0.01700173 0.02683168 0.02692947 0.01962454 0.0258623  0.02133289\n",
      " 0.02380192 0.01863052 0.01796431 0.03378449 0.03397466 0.03569495\n",
      " 0.01370621 0.02039243 0.02208233 0.03616231 0.03908184 0.02593152\n",
      " 0.01913542 0.02628735 0.02545425 0.01887499 0.0209052  0.01942379\n",
      " 0.02161301 0.01605007 0.03813799 0.02828757 0.0137431  0.03947263\n",
      " 0.0192464  0.0403681  0.05433967 0.06212915 0.05804428 0.04555258\n",
      " 0.06924377 0.08252791 0.02296543 0.0307375  0.01736391 0.04640848\n",
      " 0.04946933 0.02464043 0.02190827 0.02791355 0.01355642 0.03456625\n",
      " 0.02100346 0.01858163 0.03070401 0.02491242]\n",
      "Label: 5541\n",
      "\n",
      "Data: [0.02048639 0.06815587 0.07595388 0.05384595 0.03950595 0.04549285\n",
      " 0.06339472 0.04924158 0.04652474 0.03817677 0.02620878 0.036029\n",
      " 0.0425893  0.04803808 0.08207516 0.04081258 0.03807449 0.03824418\n",
      " 0.03181487 0.03690614 0.02497258 0.03165324 0.03951563 0.03005129\n",
      " 0.03309371 0.02351298 0.0584346  0.02596975 0.04462237 0.02780509\n",
      " 0.04711002 0.031101   0.02774026 0.02633995 0.02549095 0.02821159\n",
      " 0.03241341 0.03902669 0.04071562 0.03494272 0.0239607  0.0337894\n",
      " 0.02488592 0.03434766 0.03015517 0.0290783  0.04231685 0.03440645\n",
      " 0.04312589 0.03831859 0.02416188 0.02465404 0.02571651 0.02900153\n",
      " 0.03105287 0.03440241 0.03905924 0.04490475 0.02433589 0.02025723\n",
      " 0.03739571 0.0318369  0.0262357  0.03205376 0.02852327 0.03142368\n",
      " 0.02949478 0.02517219 0.02430473 0.02689203 0.02287801 0.03056464\n",
      " 0.03538088 0.03314142 0.02614254 0.02802493 0.04186219 0.03397118\n",
      " 0.05457902 0.02464926 0.03384768 0.0338605  0.0330671  0.03832576\n",
      " 0.02747011 0.02885335 0.02722651 0.03559147 0.04992671 0.03129308\n",
      " 0.03373173 0.0336012  0.03431743 0.0416209  0.02184074 0.03184175\n",
      " 0.02742359 0.03465202 0.03819741 0.02729686 0.02023328 0.03864125\n",
      " 0.04232402 0.0299328  0.02502271 0.03466914]\n",
      "Label: 5541\n",
      "\n",
      "Data: [0.0153205  0.08704105 0.10461378 0.07253283 0.03911356 0.04785984\n",
      " 0.05857984 0.04959433 0.0613226  0.04875411 0.0433858  0.0490457\n",
      " 0.04815447 0.04336179 0.0466352  0.04894026 0.03363094 0.05407223\n",
      " 0.04443549 0.03339707 0.02418586 0.0282267  0.01983367 0.02467123\n",
      " 0.0303823  0.02594602 0.04414614 0.04484088 0.04904656 0.02463898\n",
      " 0.03176648 0.02221581 0.03636474 0.02864761 0.02653662 0.03652564\n",
      " 0.03332952 0.03231385 0.0545399  0.02954968 0.02906678 0.02601776\n",
      " 0.02107979 0.0422954  0.04199878 0.03478647 0.04485138 0.02964519\n",
      " 0.03299587 0.05609651 0.02476537 0.03633385 0.02553066 0.02349751\n",
      " 0.03344688 0.02420042 0.03685017 0.02882893 0.02618665 0.0299864\n",
      " 0.02693941 0.03059814 0.01971775 0.03342524 0.03529641 0.04743805\n",
      " 0.02912815 0.02742074 0.02851009 0.04087903 0.04057369 0.03801892\n",
      " 0.03416478 0.02949753 0.02803902 0.03365859 0.03250306 0.02936947\n",
      " 0.02475226 0.02227379 0.03836031 0.03123382 0.02536711 0.02818756\n",
      " 0.02564204 0.04671298 0.04010477 0.03494279 0.04083447 0.03483479\n",
      " 0.04399243 0.05409013 0.02777215 0.03689067 0.03410315 0.04582478\n",
      " 0.03408518 0.03731915 0.02411436 0.03133779 0.01619827 0.03398109\n",
      " 0.03810541 0.02859798 0.04001676 0.02453393]\n",
      "Label: 7997\n",
      "\n",
      "Data: [0.02932026 0.10950968 0.16333082 0.06843589 0.08032812 0.06490698\n",
      " 0.06692045 0.07264765 0.11030214 0.06442312 0.05425829 0.06774305\n",
      " 0.04346083 0.06223715 0.06436563 0.05047671 0.07141409 0.07193437\n",
      " 0.0606861  0.05083251 0.03180964 0.03840688 0.03664127 0.04678026\n",
      " 0.04110145 0.03409367 0.07031611 0.05249767 0.06191679 0.04686952\n",
      " 0.0334827  0.03015065 0.05241452 0.03540496 0.04174262 0.05260473\n",
      " 0.0516058  0.05026441 0.06267844 0.05105719 0.03242065 0.03879449\n",
      " 0.03378849 0.0539771  0.04307752 0.04852075 0.04887185 0.04176524\n",
      " 0.04081541 0.07779688 0.03142144 0.06298035 0.02830047 0.03756775\n",
      " 0.04820034 0.0501143  0.0667918  0.062064   0.0456237  0.04727378\n",
      " 0.04915416 0.03445714 0.02510894 0.06151611 0.04684445 0.04447306\n",
      " 0.04063963 0.03243625 0.04251034 0.0485158  0.05395301 0.04081408\n",
      " 0.03755326 0.05546016 0.04305488 0.04539901 0.04365717 0.04573919\n",
      " 0.04464395 0.02495958 0.05121047 0.03980101 0.02833015 0.05353642\n",
      " 0.04141345 0.05853013 0.05935543 0.05335659 0.0649149  0.05449562\n",
      " 0.05995907 0.05352433 0.04685333 0.05414599 0.04639451 0.0580582\n",
      " 0.080529   0.0595215  0.03392493 0.04710608 0.03773479 0.05695222\n",
      " 0.04322899 0.03837254 0.04414554 0.04095625]\n",
      "Label: 7997\n",
      "\n",
      "Data: [0.06424084 0.1645009  0.15654029 0.15254524 0.13189584 0.1155965\n",
      " 0.13223456 0.12884697 0.11679    0.10600578 0.11286473 0.1155185\n",
      " 0.13569999 0.10401563 0.13202737 0.11152402 0.10949195 0.12307608\n",
      " 0.10288077 0.07315906 0.07285006 0.08704284 0.07597018 0.07644197\n",
      " 0.11861556 0.10457386 0.09524477 0.09426708 0.13181707 0.07721794\n",
      " 0.08818906 0.09265173 0.09037405 0.08638006 0.07367387 0.10869645\n",
      " 0.09730977 0.10392409 0.10296539 0.09129121 0.08370144 0.0924795\n",
      " 0.07027397 0.10632111 0.10222624 0.09268314 0.10336807 0.08272485\n",
      " 0.07948735 0.11036659 0.06929087 0.07887864 0.08462393 0.08703627\n",
      " 0.09997325 0.09389495 0.10806739 0.10265093 0.07580661 0.07595639\n",
      " 0.08484848 0.08542266 0.07269115 0.0856505  0.10392301 0.09712948\n",
      " 0.09359408 0.08091254 0.08288301 0.09660248 0.09752626 0.09729464\n",
      " 0.09994192 0.11078375 0.08231671 0.11803398 0.08854849 0.08623999\n",
      " 0.09586037 0.07786174 0.0846242  0.09193128 0.07549602 0.09890569\n",
      " 0.08393709 0.1037019  0.10221978 0.09117107 0.11296564 0.10572678\n",
      " 0.10560343 0.10041058 0.07997863 0.09909578 0.07438824 0.10524407\n",
      " 0.08819576 0.10700116 0.08199016 0.09243672 0.06391764 0.08831002\n",
      " 0.09287895 0.10096634 0.08222485 0.08253304]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.04785627 0.11027698 0.14970857 0.09347803 0.09165379 0.07898924\n",
      " 0.08785128 0.11890687 0.10536177 0.09444713 0.0737195  0.06702425\n",
      " 0.09221346 0.06410202 0.11512251 0.08792038 0.09025017 0.06498516\n",
      " 0.06789967 0.04500729 0.05656492 0.0589156  0.06830108 0.06458773\n",
      " 0.08001167 0.06446627 0.10077927 0.05734852 0.08176999 0.04773711\n",
      " 0.05826133 0.05023554 0.06207961 0.05298872 0.04892018 0.06379991\n",
      " 0.07466687 0.0922709  0.05269375 0.08345791 0.04411141 0.04822138\n",
      " 0.04570428 0.06991591 0.06666507 0.06638845 0.06437475 0.05389065\n",
      " 0.05606858 0.09091974 0.04827128 0.0554046  0.03591879 0.07294266\n",
      " 0.06241664 0.05238434 0.08392689 0.08920868 0.04742287 0.04272981\n",
      " 0.04873516 0.08009325 0.0390282  0.06154436 0.06452481 0.06290971\n",
      " 0.07059433 0.06915039 0.04179326 0.04650827 0.04433018 0.07113972\n",
      " 0.05117434 0.06363278 0.05191798 0.0716659  0.06346463 0.04988959\n",
      " 0.07090184 0.0358782  0.07012587 0.06319635 0.04313928 0.07678135\n",
      " 0.05639483 0.0587584  0.0604051  0.07053425 0.07395332 0.06900319\n",
      " 0.07023212 0.07008374 0.05826073 0.07713712 0.04904426 0.06614616\n",
      " 0.0814447  0.070826   0.06493151 0.08686741 0.06689199 0.06871502\n",
      " 0.06563693 0.07509778 0.05546663 0.06093007]\n",
      "Label: 5812\n",
      "\n",
      "Data: [0.01097287 0.1162317  0.06301524 0.04350806 0.05261881 0.04842553\n",
      " 0.0394251  0.03121632 0.02502693 0.03078287 0.01944939 0.03129955\n",
      " 0.03145654 0.02656988 0.0309037  0.02725363 0.0288057  0.03923448\n",
      " 0.02362356 0.01834794 0.01233894 0.02403878 0.01718509 0.0145893\n",
      " 0.02632886 0.02331134 0.01766155 0.02659662 0.02442098 0.0119099\n",
      " 0.01832368 0.01493278 0.03133457 0.01863013 0.01786932 0.03439093\n",
      " 0.02252124 0.03289079 0.02347517 0.03838562 0.01371747 0.02999965\n",
      " 0.01382651 0.02575959 0.01934575 0.01997792 0.0263864  0.01328583\n",
      " 0.02363044 0.02644952 0.01122404 0.0195596  0.01066971 0.01871834\n",
      " 0.01585204 0.01732119 0.02800171 0.02564176 0.01333125 0.01085173\n",
      " 0.02716192 0.02874953 0.01158533 0.01998157 0.01910978 0.02646332\n",
      " 0.02186564 0.02610335 0.01786731 0.01728171 0.02381111 0.01436606\n",
      " 0.02658921 0.03393262 0.01869627 0.02802243 0.01956156 0.01889092\n",
      " 0.02417203 0.01186606 0.01960975 0.01827345 0.01343115 0.02278275\n",
      " 0.02045065 0.0210194  0.02363813 0.01618028 0.01991514 0.02351427\n",
      " 0.02794135 0.02276016 0.0185451  0.02315992 0.0174718  0.0255833\n",
      " 0.02038647 0.01699603 0.01909965 0.01907482 0.01368317 0.02992585\n",
      " 0.02757496 0.02204403 0.01861421 0.01602013]\n",
      "Label: 5499\n",
      "\n",
      "Data: [0.04194486 0.14336514 0.10580505 0.09585013 0.10074853 0.06175051\n",
      " 0.10383283 0.08024918 0.07511356 0.08687783 0.06451551 0.07170163\n",
      " 0.07457705 0.0741632  0.07935849 0.08448228 0.08198874 0.0873672\n",
      " 0.0636619  0.0460331  0.04822763 0.05513209 0.05095991 0.05025043\n",
      " 0.05682438 0.05929355 0.07187778 0.05317935 0.06237372 0.0484033\n",
      " 0.06205062 0.04860814 0.06976388 0.04533751 0.05744622 0.07928975\n",
      " 0.06505239 0.08216666 0.0663597  0.0613126  0.0484731  0.07334736\n",
      " 0.05363081 0.07462455 0.05282442 0.07009223 0.06285923 0.05235417\n",
      " 0.06531442 0.0729749  0.04362432 0.04251445 0.04357324 0.0425182\n",
      " 0.05446563 0.0501477  0.07828982 0.07555681 0.0461458  0.05014326\n",
      " 0.0596996  0.058888   0.05341955 0.06269007 0.07173033 0.05640232\n",
      " 0.0575359  0.06458684 0.0643494  0.05205134 0.06137706 0.06011556\n",
      " 0.07032881 0.06355665 0.05260731 0.0841111  0.05508538 0.0530785\n",
      " 0.05759754 0.03494088 0.06411836 0.06185127 0.04727412 0.06449533\n",
      " 0.05763683 0.05895927 0.06444611 0.0574651  0.05283948 0.07438472\n",
      " 0.05888291 0.07049894 0.0624265  0.06035394 0.05443292 0.05759592\n",
      " 0.06679894 0.06078571 0.05592533 0.06098528 0.04684262 0.07183196\n",
      " 0.08739109 0.07196371 0.05414051 0.04452845]\n",
      "Label: 5499\n",
      "\n",
      "Data: [0.03922712 0.1626558  0.1327293  0.09086748 0.0860865  0.08059831\n",
      " 0.07573502 0.06623416 0.05940086 0.09735554 0.06549462 0.08117424\n",
      " 0.06618965 0.06919531 0.06974804 0.07753558 0.07863009 0.08169628\n",
      " 0.06023288 0.04969517 0.03615991 0.05124796 0.0437997  0.04426214\n",
      " 0.0759193  0.06221748 0.05531744 0.07090602 0.06952642 0.04619159\n",
      " 0.05327607 0.04244642 0.06933164 0.04583722 0.05479858 0.05955045\n",
      " 0.05971705 0.0771175  0.06509045 0.08022819 0.04375287 0.05827967\n",
      " 0.04749344 0.07208277 0.06083477 0.05013005 0.06850378 0.03980972\n",
      " 0.06665774 0.06574243 0.03532858 0.04730028 0.04048716 0.05783092\n",
      " 0.0515986  0.04511224 0.06263698 0.06461941 0.0348832  0.03909102\n",
      " 0.06035165 0.06476711 0.03880752 0.0435671  0.05611158 0.06243766\n",
      " 0.06275613 0.05945355 0.05106379 0.05071982 0.0578416  0.05633514\n",
      " 0.07732119 0.07575424 0.04431773 0.06145509 0.04862508 0.05499003\n",
      " 0.06337947 0.03996589 0.05143801 0.05732669 0.04480227 0.05310322\n",
      " 0.05511036 0.04680286 0.06103246 0.05757485 0.0563665  0.05306189\n",
      " 0.05924208 0.06060129 0.04955878 0.05543469 0.04583178 0.06451397\n",
      " 0.05517748 0.05349821 0.05983485 0.05690521 0.0374127  0.06195613\n",
      " 0.07952867 0.06530011 0.05113506 0.04493791]\n",
      "Label: 5311\n",
      "\n",
      "Data: [0.04450667 0.14176804 0.17227669 0.11705115 0.08561568 0.09547225\n",
      " 0.10176972 0.10081052 0.09926687 0.09957222 0.08723613 0.08034725\n",
      " 0.08898496 0.07818101 0.10080561 0.09439573 0.10572609 0.0889491\n",
      " 0.08615154 0.06197222 0.06342162 0.05700509 0.06966349 0.08079175\n",
      " 0.09143126 0.06429816 0.09585171 0.07466216 0.10903621 0.07485941\n",
      " 0.08108176 0.06541564 0.06799435 0.05036436 0.05834574 0.08085299\n",
      " 0.09104403 0.08274215 0.06648474 0.07938429 0.05510605 0.05939831\n",
      " 0.06764867 0.08001392 0.07458529 0.08386377 0.07823469 0.07297466\n",
      " 0.07948702 0.07954055 0.06371266 0.06899419 0.05925868 0.06482157\n",
      " 0.06896927 0.06458996 0.08037261 0.08900862 0.06275137 0.06375093\n",
      " 0.06751624 0.07201409 0.05110557 0.06491674 0.08183061 0.06718272\n",
      " 0.0612844  0.06689319 0.0599576  0.06684176 0.06378975 0.0817571\n",
      " 0.07698566 0.07419369 0.0611018  0.07384863 0.07744955 0.06923359\n",
      " 0.0761014  0.05375411 0.07468877 0.07848439 0.06488726 0.0796554\n",
      " 0.06878705 0.0849253  0.0669537  0.07474138 0.08454324 0.08621022\n",
      " 0.0684794  0.08323558 0.07917593 0.07692881 0.06127433 0.07990649\n",
      " 0.07360431 0.07876208 0.06350283 0.07067043 0.06093723 0.0654425\n",
      " 0.09260792 0.08513351 0.0570374  0.07239442]\n",
      "Label: 5311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(42):  # Print first 5 generated data points\n",
    "    print(\"Data:\", generated_text_data[i])\n",
    "    print(\"Label:\", labels[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ab4b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6b9ff57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01490041, 0.08570764, 0.06577703, ..., 0.02652592, 0.02899845,\n",
       "        0.02600318],\n",
       "       [0.02960384, 0.13428085, 0.14453222, ..., 0.04867433, 0.07115109,\n",
       "        0.0456026 ],\n",
       "       [0.01333384, 0.06149215, 0.11685329, ..., 0.0221905 , 0.02723243,\n",
       "        0.01918064],\n",
       "       ...,\n",
       "       [0.04194486, 0.14336514, 0.10580505, ..., 0.07196371, 0.05414051,\n",
       "        0.04452845],\n",
       "       [0.03922712, 0.1626558 , 0.1327293 , ..., 0.06530011, 0.05113506,\n",
       "        0.04493791],\n",
       "       [0.04450667, 0.14176804, 0.17227669, ..., 0.08513351, 0.0570374 ,\n",
       "        0.07239442]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1b662a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 301.8/301.8 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.5.15-cp310-cp310-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 269.0/269.0 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\nasir hussain\\documents\\rafay\\tfvenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "168a0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"Spending_Pattern_Dataset.xlsx\") \n",
    "\n",
    "# Data cleaning and preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "data['clean_Merchant_Name'] = data['Merchant_Name'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c08a5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\nasir hussain\\documents\\rafay\\tfvenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 46.2/46.2 MB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nasir hussain\\documents\\rafay\\tfvenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bba2fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['clean_Merchant_Name'], data['Merchant_Name'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "max_sequence_length = max([len(x) for x in X_train_seq])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e04dbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"Spending_Pattern_Dataset.xlsx\")  # Replace \"your_dataset.csv\" with the actual filename\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['Merchant_Name'], data['MCC'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization and padding\n",
    "max_words = 10000  # Adjust this based on your vocabulary size\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "max_sequence_length = 100  # Adjust this based on the maximum length of your sequences\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "258ea7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape         </span>┃<span style=\"font-weight: bold\">     Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ ?                    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────┼──────────────────────┼─────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ ?                    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────┼──────────────────────┼─────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ ?                    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────┴──────────────────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)     │ ?                    │ \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────┼──────────────────────┼─────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)               │ ?                    │ \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────┼──────────────────────┼─────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)             │ ?                    │ \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────┴──────────────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "max_words = 10000\n",
    "embedding_dim = 100  # Adjust this based on your embedding dimension\n",
    "num_classes = len(data['Merchant_Name'].unique())\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length),\n",
    "    LSTM(128),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d84eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Nasir Hussain\\AppData\\Local\\Temp\\ipykernel_15356\\613294621.py\", line 2, in <module>\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 314, in fit\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in one_step_on_data\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 316, in compute_loss\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 43, in __call__\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1722, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 638, in sparse_categorical_crossentropy\n\nReceived a label value of 7997 which is outside the valid range of [0, 42).  Label values: 4900 5812 6012 4121 5411 5541 6211 6513 5311 6011 5712 6011 6300 5813 7997 5813 5311 5967 5812 4829 6012 5541 5812 5812 7997 5499 6012 5411 5732 4900 6300 5812\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_12109]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Nasir Hussain\\AppData\\Local\\Temp\\ipykernel_15356\\613294621.py\", line 2, in <module>\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 314, in fit\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in one_step_on_data\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 316, in compute_loss\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 43, in __call__\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1722, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1567, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Nasir Hussain\\Documents\\Rafay\\tfvenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 638, in sparse_categorical_crossentropy\n\nReceived a label value of 7997 which is outside the valid range of [0, 42).  Label values: 4900 5812 6012 4121 5411 5541 6211 6513 5311 6011 5712 6011 6300 5813 7997 5813 5311 5967 5812 4829 6012 5541 5812 5812 7997 5499 6012 5411 5732 4900 6300 5812\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_12109]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_val_pad, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc777fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
